# Weekly report for fourth development week

- 9 hours

- Convert the algorithms to use binary IO (still in a bit of an easy way, with Huffman using pickle to encode the binary tree). Add first benchmarking tests.

- What I learned
    - I formed an hypothesis for why LZ algorithms and Huffman coding are often paired together. 
        - LZ produces optimizes encoding for largest patterned parts of the input data. 
        - Huffman optimizes encoding for the most common patterns of data.
        - It seems like optimizing encoding for both the longest patterns and the most common ones would result in quite optimal solution. And I can now see why the combination would produce that result.
    - Binary IO is difficult and bug prone
    - "sCsCs" form in input causing problems for LZW is no joke. It is mentioned on the wikipedia page though, I just had missed it earlier https://en.wikipedia.org/wiki/Lempel%E2%80%93Ziv%E2%80%93Welch#Decoding_2


- Next steps are to figure out how to binary encode the huffmann tree itself correctly, and then start doing proper compression benchmarks. 

- Implementing the binary IO and tests for it was quite difficult. Still a bit unsure if my tests for it are correct. Best tests would of course be achievable if I could match the format of some CLI tool or python library that can create LZW and Huffman encoded data, because then I could use this utility for testing. My outputs correctness.


